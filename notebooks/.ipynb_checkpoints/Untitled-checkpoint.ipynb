{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401bcc02-d144-4aca-a45a-3074a459f2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import traceback\n",
    "import logging\n",
    "import re\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import pipeline\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename='chatbot.log', level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Load a pre-trained language model for code and query understanding\n",
    "nlp_model = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")\n",
    "\n",
    "# Dataset placeholder\n",
    "df = None  # To be loaded by the user\n",
    "column_mapping = {}  # Column mappings provided by the user\n",
    "\n",
    "# Optimized predefined query handler\n",
    "def predefined_query_handler(query):\n",
    "    query = query.lower()\n",
    "    operations = {\n",
    "        \"average\": \"df['{col}'].mean()\",\n",
    "        \"total\": \"df['{col}'].sum()\",\n",
    "        \"highest\": \"df['{col}'].max()\"\n",
    "    }\n",
    "    for col in df.columns:\n",
    "        for op in operations:\n",
    "            if re.search(fr\"{op} {col.lower()}\", query):\n",
    "                return operations[op].format(col=col)\n",
    "    return None\n",
    "\n",
    "def parse_query(query, dataset_context):\n",
    "    \"\"\"\n",
    "    Parse the query to identify intents and tasks.\n",
    "    Use an advanced NLU model for context-based understanding.\n",
    "    \"\"\"\n",
    "    input_text = f\"Dataset columns: {dataset_context}\\nQuery: {query}\\nGenerate the required Python code:\"\n",
    "    response = nlp_model(input_text, max_length=256, num_return_sequences=1)\n",
    "    return response[0][\"generated_text\"]\n",
    "\n",
    "def execute_generated_code(code):\n",
    "    \"\"\"\n",
    "    Execute dynamically generated Python code in a safe environment.\n",
    "    \"\"\"\n",
    "    global df\n",
    "    local_vars = {\"df\": df, \"np\": np, \"pd\": pd, \"plt\": plt, \"LinearRegression\": LinearRegression}\n",
    "    try:\n",
    "        exec(code, globals(), local_vars)\n",
    "        result = local_vars.get(\"result\", \"Operation completed successfully.\")\n",
    "        logging.info(f\"Executed code: {code}\")\n",
    "        return result, None\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Execution error: {traceback.format_exc()}\")\n",
    "        return None, f\"Execution Error:\\n{traceback.format_exc()}\"\n",
    "\n",
    "def process_query(query):\n",
    "    \"\"\"\n",
    "    Process the query, generate code, and execute it.\n",
    "    \"\"\"\n",
    "    global df, column_mapping\n",
    "\n",
    "    if df is None:\n",
    "        return \"No dataset uploaded. Please upload your dataset first.\"\n",
    "\n",
    "    # Check predefined queries first\n",
    "    predefined_code = predefined_query_handler(query)\n",
    "    if predefined_code:\n",
    "        logging.info(f\"Predefined query matched: {query}\")\n",
    "        return execute_generated_code(predefined_code)[0]\n",
    "\n",
    "    # Prepare the dataset context\n",
    "    dataset_context = \", \".join([f\"{key} -> {value}\" for key, value in column_mapping.items()])\n",
    "    generated_code = parse_query(query, dataset_context)\n",
    "\n",
    "    print(f\"\\nGenerated Code:\\n{generated_code}\\n\")  # Debugging/verification purposes\n",
    "    logging.info(f\"Generated code for query '{query}': {generated_code}\")\n",
    "\n",
    "    # Execute the generated code\n",
    "    result, error = execute_generated_code(generated_code)\n",
    "    if error:\n",
    "        return error\n",
    "    return result\n",
    "\n",
    "def chatbot():\n",
    "    \"\"\"\n",
    "    Run the intelligent chatbot interface.\n",
    "    \"\"\"\n",
    "    global df, column_mapping\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"age\": [25, 30, 45, 50],\n",
    "        \"sales\": [200, 300, 400, 500],\n",
    "        \"profit\": [20, 30, 40, 50]\n",
    "    })\n",
    "    column_mapping = {\"Age\": \"age\", \"Sales\": \"sales\", \"Profit\": \"profit\"}\n",
    "    print(\"Sample dataset loaded. Column mappings preloaded.\")\n",
    "\n",
    "    print(\"\\nChatbot is ready. Type your queries!\")\n",
    "    while True:\n",
    "        user_input = input(\"\\nYou: \")\n",
    "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "            print(\"Chatbot: Goodbye!\")\n",
    "            break\n",
    "        response = process_query(user_input)\n",
    "        print(f\"Chatbot: {response}\")\n",
    "\n",
    "if _name_ == \"_main_\":\n",
    "    chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77c6b247-f71a-4a04-8555-e715362345ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import traceback\n",
    "import logging\n",
    "import re\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ad67c47-a73f-465c-b1bb-4b8cad544fe5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1563b1f415ad4af5999f43c1b0046b8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rahul\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Rahul\\.cache\\huggingface\\hub\\models--google--flan-t5-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93be561fa17d4de0b7cf7d98e57d7ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d84ad1d4ca4526bca5a39cb85b37e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a894ef7fb3547aeb7c09b4684dfec30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40543c26d2194972a6567961f20656d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49c817550c534d95bea40b09cd95b989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "550f3e543cea4efdaed64273f2dccfde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(filename='chatbot.log', level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Load a pre-trained language model for code and query understanding\n",
    "nlp_model = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")\n",
    "\n",
    "# Dataset placeholder\n",
    "df = pd.read_excel(r\"E:\\BE Project\\Backend\\project_root\\data\\Online Retail.xlsx\")  # To be loaded by the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5740c446-8346-4ccc-9d5e-584528637009",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping = {\"InvoiceNo\": \"invoice number\", \"StockCode\": \"product code\", \"Description\": \"description\", \"Quantity\": \"quantity\", \"InvoiceDate\":\"invoice date\", \"UnitPrice\":\"price\", \"CustomerID\":\"customer id\", \"Country\":\"country\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d1990a-9c59-4d0a-840d-4fb084b3f53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predefined_query_handler(query):\n",
    "    query = query.lower()\n",
    "    operations = {\n",
    "        \"average\": \"df['{col}'].mean()\",\n",
    "        \"total\": \"df['{col}'].sum()\",\n",
    "        \"highest\": \"df['{col}'].max()\"\n",
    "    }\n",
    "    for col in df.columns:\n",
    "        for op in operations:\n",
    "            if re.search(fr\"{op} {col.lower()}\", query):\n",
    "                return operations[op].format(col=col)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b024aa-a10f-4720-8bdd-c6da8f2cefb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_query(query, dataset_context):\n",
    "    input_text = f\"Dataset columns: {dataset_context}\\nQuery: {query}\\nGenerate the required Python code:\"\n",
    "    response = nlp_model(input_text, max_length=256, num_return_sequences=1)\n",
    "    return response[0][\"generated_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2df2211-9e79-459d-9b51-9c2dfad276dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_generated_code(code):\n",
    "    global df\n",
    "    local_vars = {\"df\": df, \"np\": np, \"pd\": pd, \"plt\": plt, \"LinearRegression\": LinearRegression}\n",
    "    try:\n",
    "        exec(code, globals(), local_vars)\n",
    "        result = local_vars.get(\"result\", \"Operation completed successfully.\")\n",
    "        logging.info(f\"Executed code: {code}\")\n",
    "        return result, None\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Execution error: {traceback.format_exc()}\")\n",
    "        return None, f\"Execution Error:\\n{traceback.format_exc()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcc1f9c-0adb-43a4-bc5f-c2a016a83f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(query):\n",
    "    global df, column_mapping\n",
    "\n",
    "    if df is None:\n",
    "        return \"No dataset uploaded. Please upload your dataset first.\"\n",
    "\n",
    "    # Check predefined queries first\n",
    "    predefined_code = predefined_query_handler(query)\n",
    "    if predefined_code:\n",
    "        logging.info(f\"Predefined query matched: {query}\")\n",
    "        return execute_generated_code(predefined_code)[0]\n",
    "\n",
    "    # Prepare the dataset context\n",
    "    dataset_context = \", \".join([f\"{key} -> {value}\" for key, value in column_mapping.items()])\n",
    "    generated_code = parse_query(query, dataset_context)\n",
    "\n",
    "    print(f\"\\nGenerated Code:\\n{generated_code}\\n\")  \n",
    "    logging.info(f\"Generated code for query '{query}': {generated_code}\")\n",
    "\n",
    "    # Execute the generated code\n",
    "    result, error = execute_generated_code(generated_code)\n",
    "    if error:\n",
    "        return error\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012f3171-5ee9-4a8f-95ef-072237e81bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot():\n",
    "    global df, column_mapping\n",
    "    \n",
    "    print(\"Sample dataset loaded. Column mappings preloaded.\")\n",
    "\n",
    "    print(\"\\nChatbot is ready. Type your queries!\")\n",
    "    while True:\n",
    "        user_input = input(\"\\nYou: \")\n",
    "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "            print(\"Chatbot: Goodbye!\")\n",
    "            break\n",
    "        response = process_query(user_input)\n",
    "        print(f\"Chatbot: {response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
